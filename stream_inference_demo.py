import os
import torch
import torchaudio
from networks.semantic_codec.model_loader import load_encoder, load_decoder


def stream_decode_tokens(
    codec_decoder, 
    semantic_tokens, 
    acoustic_tokens, 
    decode_token_numbers: int = 50, 
    device: str = 'cpu',
    sample_rate: int = 24000
) -> torch.Tensor:
    """
    Stream decode tokens to generate audio in a streaming fashion.
    
    Args:
        codec_decoder: Pre-trained decoder model
        semantic_tokens: List of semantic tokens
        acoustic_tokens: List of acoustic tokens (multiple codebooks)
        decode_token_numbers: Number of tokens to decode
        device: Device to run computation on ('cpu' or 'cuda')
        sample_rate: Sample rate of output audio (default: 24000)
        
    Returns:
        torch.Tensor: Generated audio waveform
    """
    lookahead_num = 3  # do not change
    lstm_buffer_length = 8  # do not change
    samples_per_frame = sample_rate // 1000 * 60  # 60ms * sample_rate
    
    # Convert tokens to tensors and move to device
    semantic_tokens = torch.tensor(semantic_tokens).int().to(device)
    acoustic_tokens = torch.tensor(acoustic_tokens).int().to(device)
    n_acoustic_codebooks = acoustic_tokens.shape[0]
    
    # Initialize streaming input with first 4 (lookahead_num + 1) tokens
    stream_semantic_codes = semantic_tokens[:lookahead_num + 1].unsqueeze(0)  # [1, 1, lookahead_num + 1]
    stream_acoustic_codes = acoustic_tokens[:, :lookahead_num + 1].unsqueeze(0)  # [1, n_codebooks, lookahead_num + 1]

    # Get hidden size from decoder memory layers
    mem_layer_hidden_size = codec_decoder.decoder.mem_layers[0].hidden_size

    # Initialize LSTM hidden states for streaming
    list1_h = torch.zeros(1, 1, mem_layer_hidden_size).to(device)
    list1_c = torch.zeros(1, 1, mem_layer_hidden_size).to(device)
    list2_h = torch.zeros(1, 1, mem_layer_hidden_size).to(device)
    list2_c = torch.zeros(1, 1, mem_layer_hidden_size).to(device)
    lstm_buffer = torch.zeros(1, mem_layer_hidden_size, lstm_buffer_length).to(device)
    
    # Initialize output audio buffer
    stream_audio_out = torch.zeros(1, 1, 0).to(device)

    # Adjust decode length if exceeds available tokens
    if decode_token_numbers > semantic_tokens.shape[-1]:
        decode_token_numbers = semantic_tokens.shape[-1]

    # Stream processing frame by frame
    for i in range(lookahead_num, decode_token_numbers):
        # Run decoder forward pass in streaming mode
        stream_audio, list1_h, list1_c, list2_h, list2_c, lstm_buffer = codec_decoder.forward_stream(
            stream_semantic_codes, 
            stream_acoustic_codes, 
            list1_h, 
            list1_c, 
            list2_h, 
            list2_c, 
            lstm_buffer
        )
        
        # Extract and concatenate audio output
        stream_audio_out = torch.cat([
            stream_audio_out, 
            stream_audio[:, :, -(lookahead_num + 1) * samples_per_frame:-lookahead_num * samples_per_frame].clone()
        ], dim=2)

        # Update input tokens for next iteration (single token)
        stream_semantic_codes = semantic_tokens[i].unsqueeze(0).unsqueeze(0)
        stream_acoustic_codes = acoustic_tokens[:, i].unsqueeze(0).unsqueeze(-1)

    return stream_audio_out


def main():
    """
    Main function to demonstrate streaming token decoding.
    """
    # Model configuration
    decoder24k_config_path = 'configs/LongCatAudioCodec_decoder_24k_4codebooks.yaml'
    sample_rate = 24000
    
    # Device setup
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    
    # Load pre-trained decoder
    decoder24k = load_decoder(decoder24k_config_path, device)

    # Example tokens (generated by LongCat-Flash-Omni)
    semantic_tokens = [
        3138, 2623, 2293, 4096, 1027, 6918, 6918, 6918, 6918, 7180, 
        2362, 2362, 7597, 7597, 7423, 1042, 72, 1845, 8043, 1629, 
        2325, 5572, 5572, 1360, 4309, 4309, 4309, 4309, 7180, 2362, 
        2362, 7597, 7597, 7423, 113, 4778, 8039, 849, 6815, 1424, 
        4770, 7961, 5620, 6563, 5012, 503, 503, 3315, 3561, 3561, 
        3561, 7180, 7597, 7597, 257, 257, 3138, 6366, 713, 7110
    ]
    
    acoustic_tokens = [
        [3294, 1583, 5611, 882, 2020, 5907, 6211, 4668, 5132, 3326, 5186, 5186, 
         685, 2606, 2606, 6161, 3585, 5937, 4230, 3043, 3153, 5925, 4523, 4636, 
         2046, 4634, 5814, 2606, 685, 1315, 1315, 2336, 2606, 2606, 6161, 6241, 
         6879, 5602, 6830, 6757, 3787, 4591, 4748, 3779, 4605, 2054, 6917, 5601, 
         2668, 822, 5666, 2606, 2336, 2336, 2336, 2336, 7628, 7190, 644, 6873], 
        [3578, 2646, 6422, 114, 6574, 2747, 5357, 502, 3529, 850, 4945, 1255, 
         6082, 4372, 4290, 7820, 8023, 2807, 6295, 4867, 1305, 8076, 1239, 2619, 
         2810, 1307, 6394, 836, 3472, 1042, 1042, 3147, 4372, 4282, 7764, 5725, 
         1594, 4894, 4373, 1599, 4991, 314, 5926, 2150, 4239, 2802, 4702, 3293, 
         2015, 5053, 5035, 4350, 3147, 3147, 3147, 3147, 7448, 458, 6422, 5303], 
        [4512, 3004, 6907, 4349, 4779, 7358, 793, 677, 1909, 3863, 1431, 1504, 
         4036, 4754, 4520, 3847, 1162, 5099, 3253, 1937, 4691, 3403, 6100, 1716, 
         997, 997, 6725, 4001, 4724, 5294, 5294, 5294, 6734, 1548, 3846, 3346, 
         5041, 7384, 5337, 6503, 1024, 2022, 3477, 2761, 4887, 4257, 8058, 3872, 
         3979, 7543, 3757, 794, 794, 5294, 5294, 5294, 1454, 819, 700, 429]
    ]

    # Tokens to be decoded
    decode_token_numbers = 60
    print(f'Decode {decode_token_numbers} tokens of total {len(semantic_tokens)}')
    
    # Run streaming decoding
    stream_audio_out = stream_decode_tokens(
        decoder24k, 
        semantic_tokens, 
        acoustic_tokens, 
        decode_token_numbers=decode_token_numbers, 
        device=device
    )

    # Save generated audio
    file_path_out = 'demos/stream_demo/test_stream.wav'
    torchaudio.save(
        file_path_out, 
        stream_audio_out.detach().squeeze(0).to('cpu'), 
        sample_rate
    )


if __name__ == "__main__":
    main()
